{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "denoiser.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZXaWXBnMP_e"
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "\n",
        "import os\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9U7wywtOMTT7"
      },
      "source": [
        "import glob\n",
        "trainfilenames = glob.glob(os.path.join('../input/trainrecords2/TrainRecords2', 'trainrecords*'))\n",
        "train2filenames=glob.glob(os.path.join('../input/trainrecords3/TrainRecords', 'trainrecords*'))\n",
        "train3filenames=glob.glob(os.path.join('../input/train-records-57k', 'trainrecords*'))\n",
        "trainfilenames=trainfilenames+train2filenames+train3filenames\n",
        "valfilenames = glob.glob(os.path.join('../input/val-records', 'valrecords*'))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qopwQO3JMVVW"
      },
      "source": [
        "def tf_record_parser(record):\n",
        "    keys_to_features = {\n",
        "        \"noise_stft_phase\": tf.io.FixedLenFeature((), tf.string, default_value=\"\"),\n",
        "        'noise_stft_mag_features': tf.io.FixedLenFeature([], tf.string),\n",
        "        \"clean_stft_magnitude\": tf.io.FixedLenFeature((), tf.string)\n",
        "    }\n",
        "\n",
        "    features = tf.io.parse_single_example(record, keys_to_features)\n",
        "\n",
        "    noise_stft_mag_features = tf.io.decode_raw(features['noise_stft_mag_features'], tf.float32)\n",
        "    clean_stft_magnitude = tf.io.decode_raw(features['clean_stft_magnitude'], tf.float32)\n",
        "    noise_stft_phase = tf.io.decode_raw(features['noise_stft_phase'], tf.float32)\n",
        "\n",
        "    # reshape input and annotation images\n",
        "    noise_stft_mag_features = tf.reshape(noise_stft_mag_features, (129, 8, 1), name=\"noise_stft_mag_features\")\n",
        "    clean_stft_magnitude = tf.reshape(clean_stft_magnitude, (129, 1, 1), name=\"clean_stft_magnitude\")\n",
        "    noise_stft_phase = tf.reshape(noise_stft_phase, (129,), name=\"noise_stft_phase\")\n",
        "\n",
        "    return noise_stft_mag_features, clean_stft_magnitude"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3OXp0lAMXL1"
      },
      "source": [
        "import tensorflow as tf\n",
        "train_dataset = tf.data.TFRecordDataset(trainfilenames[:-1])\n",
        "train_dataset = train_dataset.map(tf_record_parser)\n",
        "train_dataset = train_dataset.shuffle(8192)\n",
        "train_dataset = train_dataset.repeat()\n",
        "train_dataset = train_dataset.batch(512)\n",
        "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_gEu6YMMXRD"
      },
      "source": [
        "print(len(trainfilenames))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMT3dlSMMXT-"
      },
      "source": [
        "val_dataset = tf.data.TFRecordDataset([valfilenames])\n",
        "val_dataset = val_dataset.map(tf_record_parser)\n",
        "val_dataset = val_dataset.repeat(1)\n",
        "val_dataset = val_dataset.batch(512)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwqT3GlsMdv6"
      },
      "source": [
        "from tensorflow.keras.layers import Conv2D, Input, LeakyReLU, Flatten, Dense, Reshape, Conv2DTranspose, BatchNormalization, Activation\n",
        "from tensorflow.keras import Model, Sequential\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "648wizxUMdyb"
      },
      "source": [
        "def conv_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
        "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(0.0006))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  if use_bn:\n",
        "    x = BatchNormalization()(x)\n",
        "  return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RXNKGZ0NMd1F"
      },
      "source": [
        "def full_pre_activation_block(x, filters, kernel_size, strides, padding='same', use_bn=True):\n",
        "  shortcut = x\n",
        "  in_channels = x.shape[-1]\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(filters=filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "\n",
        "  x = BatchNormalization()(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = Conv2D(filters=in_channels, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "\n",
        "  return shortcut + x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HzgudzpMMd3l"
      },
      "source": [
        "\n",
        "def build_model(l2_strength):\n",
        "  inputs = Input(shape=[numFeatures,numSegments,1])\n",
        "  x = inputs\n",
        "\n",
        "  # -----\n",
        "  x = tf.keras.layers.ZeroPadding2D(((4,4), (0,0)))(x)\n",
        "  x = Conv2D(filters=18, kernel_size=[9,8], strides=[1, 1], padding='valid', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  skip0 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(skip0)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # -----\n",
        "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  skip1 = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "                 kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(skip1)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # ----\n",
        "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "  \n",
        "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # ----\n",
        "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = x + skip1\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # ----\n",
        "  x = Conv2D(filters=18, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=30, kernel_size=[5,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "             kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = x + skip0\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  x = Conv2D(filters=8, kernel_size=[9,1], strides=[1, 1], padding='same', use_bias=False,\n",
        "              kernel_regularizer=tf.keras.regularizers.l2(l2_strength))(x)\n",
        "  x = Activation('relu')(x)\n",
        "  x = BatchNormalization()(x)\n",
        "\n",
        "  # ----\n",
        "  x = tf.keras.layers.SpatialDropout2D(0.2)(x)\n",
        "  x = Conv2D(filters=1, kernel_size=[129,1], strides=[1, 1], padding='same')(x)\n",
        "\n",
        "  model = Model(inputs=inputs, outputs=x)\n",
        "\n",
        "  optimizer = tf.keras.optimizers.Adam(3e-4)\n",
        "  #optimizer = RAdam(total_steps=10000, warmup_proportion=0.1, min_lr=3e-4)\n",
        "\n",
        "  model.compile(optimizer=optimizer, loss='mse', \n",
        "                metrics=[tf.keras.metrics.RootMeanSquaredError('rmse')])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EruBOn2SMd6T"
      },
      "source": [
        "model = build_model(l2_strength=0.0)\n",
        "model.summary()\n",
        "\n",
        "tf.keras.utils.plot_model(model, show_shapes=True, dpi=64)\n",
        "\n",
        "%tensorboard --logdir logs\n",
        "\n",
        "baseline_val_loss = model.evaluate(test_dataset)[0]\n",
        "print(f\"Baseline accuracy {baseline_val_loss}\")\n",
        "def l2_norm(vector):\n",
        "    return np.square(vector)\n",
        "\n",
        "def SDR(denoised, cleaned, eps=1e-7): \n",
        "    a = l2_norm(denoised)\n",
        "    b = l2_norm(denoised - cleaned)\n",
        "    a_b = a / b\n",
        "    return np.mean(10 * np.log10(a_b + eps))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnAaH_wONHFw"
      },
      "source": [
        "early_stopping_callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True, baseline=None)\n",
        "\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, update_freq='batch')\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath='./denoiser_cnn_log_mel_generator.h5', \n",
        "                                                         monitor='val_loss', save_best_only=True)\n",
        "\n",
        "model.fit(train_dataset,\n",
        "         steps_per_epoch=600, # you might need to change this\n",
        "         validation_data=test_dataset,\n",
        "         epochs=400,\n",
        "         callbacks=[early_stopping_callback, tensorboard_callback, checkpoint_callback]\n",
        "        )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZGJ-yjBNH-q"
      },
      "source": [
        "val_loss = model.evaluate(test_dataset)[0]\n",
        "if val_loss < baseline_val_loss:\n",
        "  print(\"New model saved.\")\n",
        "  model.save('./denoiser_cnn_log_mel_generator.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFPNVW-yNMnB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Hsl7QhkNMq7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gn4L4sZKNMud"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}